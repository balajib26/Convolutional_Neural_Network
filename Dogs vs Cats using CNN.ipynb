{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, a Convolutional Neural Network is trained on Dogs vs Cats dataset from Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://www.kaggle.com/c/dogs-vs-cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil \n",
    "from tqdm import tqdm\n",
    "# Keras is the Deep Learning library built on top on Tensorflow\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test1', 'train', 'sampleSubmission.csv']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lib', 'input', 'config', 'working']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(os.listdir(\"../input\"))\n",
    "os.listdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset contains images of Cats and Dogs. A separate folder is made for cat and dog images and the \n",
    "# label of the image is found out by looking at the file name.\n",
    "if not os.path.exists(\"../train\"):\n",
    "    os.mkdir(\"../train\")\n",
    "if not os.path.exists(\"../train/dog\"):\n",
    "    os.mkdir(\"../train/dog\")\n",
    "if not os.path.exists(\"../train/cat\"):\n",
    "    os.mkdir(\"../train/cat\")\n",
    "if not os.path.exists(\"../test\"):\n",
    "    os.mkdir(\"../test\")\n",
    "if not os.path.exists(\"../test/dog\"):\n",
    "    os.mkdir(\"../test/dog\")\n",
    "if not os.path.exists(\"../test/cat\"):\n",
    "    os.mkdir(\"../test/cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [01:21<00:00, 304.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# Training images are moved to 'dog' and 'cat' folders \n",
    "for i in tqdm(os.listdir(\"../input/train/train\")):\n",
    "    if i.split(\".\")[0] == \"dog\":\n",
    "        shutil.copy2(os.path.join(\"../input/train/train\",i),os.path.join(\"../train/dog\",i))\n",
    "    elif i.split(\".\")[0] == \"cat\":\n",
    "        shutil.copy2(os.path.join(\"../input/train/train\",i),os.path.join(\"../train/cat\",i))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 34874.36it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 35387.41it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(os.listdir(\"../train/dog\")[:3000]):\n",
    "    shutil.move(os.path.join(\"../train/dog\",i),os.path.join(\"../test/dog\",i)) \n",
    "for i in tqdm(os.listdir(\"../train/cat\")[:3000]):\n",
    "    shutil.move(os.path.join(\"../train/cat\",i),os.path.join(\"../test/cat\",i)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'cat']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training data set fed to the Convolutional Neural Network model\n",
    "trainflow = ImageDataGenerator()\n",
    "traindata = trainflow.flow_from_directory(directory=\"../train\",target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Test data set fed to the Convolutional Neural Network model\n",
    "testflow = ImageDataGenerator()\n",
    "testdata = testflow.flow_from_directory(directory=\"../test\", target_size=(224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG 16 is a 16 layer Convolutional Neural Network and it uses 3x3 convolutional layers. The later layers have more depth than earlier layers because they have to learn more complex features. After  each convolutional layer, max pooling layer is used because it reduces the dimension of the layer by half which reduces the complexity and increases the computational speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/1.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 7s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# VGG16 trained on Imagenet dataset is used as a source model for transfer learning\n",
    "cnnmodel = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnnmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f1f0d6d2ba8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f1f0d6d2748>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f1f0d6d25c0>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f1f0d674e80>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f1f0d680f60>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f1f0cc66860>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f1f0cc84630>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f1f0cc84940>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f1f0cc39eb8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f1f0cbdbd68>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f1f0cc16550>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f1f0cc16668>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f1f0cbd5438>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f1f0cb71be0>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f1f0cb2bfd0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f1f0cb2b358>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f1f0caef710>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f1f6c01cdd8>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f1f0caaa908>\n"
     ]
    }
   ],
   "source": [
    "# The initial layers are not trained because we are using the same weights that performed well on imagenet dataset \n",
    "# because the target dataset is similar to source dataset.\n",
    "for layers in (cnnmodel.layers)[:19]:\n",
    "    print(layers)\n",
    "    layers.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "A= cnnmodel.layers[-2].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output layer is changed from 1000 neurons to 2 neurons because there are 2 labels, 'cat' and 'dog'\n",
    "output = Dense(2, activation=\"softmax\")(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "cdmodel = Model(input = cnnmodel.input, output = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdmodel.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 119,554,050\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cdmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"cdmodel_1.h5\", monitor='val_acc', verbose=1, save_best_only=True)\n",
    "es = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "594/594 [==============================] - 96s 162ms/step - loss: 0.0971 - accuracy: 0.9643 - val_loss: 0.3984 - val_accuracy: 0.9705\n",
      "Epoch 2/10\n",
      "  1/594 [..............................] - ETA: 1:03 - loss: 0.0017 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594/594 [==============================] - 90s 152ms/step - loss: 0.0157 - accuracy: 0.9959 - val_loss: 0.0081 - val_accuracy: 0.9713\n",
      "Epoch 3/10\n",
      "594/594 [==============================] - 90s 151ms/step - loss: 0.0055 - accuracy: 0.9996 - val_loss: 0.0991 - val_accuracy: 0.9717\n",
      "Epoch 4/10\n",
      "594/594 [==============================] - 90s 152ms/step - loss: 0.0032 - accuracy: 0.9999 - val_loss: 0.0985 - val_accuracy: 0.9725\n",
      "Epoch 5/10\n",
      "594/594 [==============================] - 92s 154ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 2.5565e-04 - val_accuracy: 0.9728\n",
      "Epoch 6/10\n",
      "594/594 [==============================] - 90s 152ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0488 - val_accuracy: 0.9730\n",
      "Epoch 7/10\n",
      "594/594 [==============================] - 90s 152ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0604 - val_accuracy: 0.9728\n",
      "Epoch 8/10\n",
      "594/594 [==============================] - 89s 150ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0891 - val_accuracy: 0.9728\n",
      "Epoch 9/10\n",
      "594/594 [==============================] - 90s 151ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 1.4901e-07 - val_accuracy: 0.9727\n",
      "Epoch 10/10\n",
      "594/594 [==============================] - 89s 149ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.1964 - val_accuracy: 0.9723\n"
     ]
    }
   ],
   "source": [
    "hist = cdmodel.fit_generator(generator= traindata, epochs= 10, validation_data= testdata, callbacks=[checkpoint,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdmodel.save_weights(\"cdmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
